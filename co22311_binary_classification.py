# -*- coding: utf-8 -*-
"""CO22311-Binary-Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/135-V04Lb07eYrnZaemb9ip7ymd2Sj5xO

Imports:
- numpy as np: Provides support for large, multi-dimensional arrays and matrices, along with mathematical functions.
- matplotlib.pyplot as plt: Used for creating static, animated, and interactive visualizations.
- pandas as pd: A powerful data analysis and data manipulation library, especially useful for handling structured data.
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""
This section of the script loads a dataset from a CSV file and extracts features and target variables for analysis or modeling."""

dataset = pd.read_csv('/content/CO22311_spambase.csv')
X = dataset.iloc[:, 1:-1].values
y = dataset.iloc[:, -1].values

"""This section of the script  displays the first few rows of the dataset."""

print(dataset.head())

"""
This section of the script splits the dataset into training and testing sets for machine learning model evaluation."""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

"""This section of the script prints the shapes of the training and testing datasets after splitting."""

print("\nShapes of the datasets:")
print(f"X_train: {X_train.shape}")
print(f"X_test: {X_test.shape}")
print(f"y_train: {y_train.shape}")
print(f"y_test: {y_test.shape}")

"""This section of the script applies feature scaling using Standardization to normalize the dataset."""

from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
sc_y = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)

"""# **Logistic Regression**

This section of the script initializes and trains a logistic regression model.
"""

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = None)
classifier.fit(X_train, y_train)

"""This section of the script uses the trained logistic regression model to make predictions on the test set."""

y_pred = classifier.predict(X_test)

"""This section of the script evaluates the performance of the trained logistic regression model using a confusion matrix.
The confusion matrix provides a summary of classification performance:
    - `cm[0,0]`: True Negatives (TN) - Correctly predicted negative cases.
    - `cm[0,1]`: False Positives (FP) - Incorrectly predicted positive cases.
    - `cm[1,0]`: False Negatives (FN) - Incorrectly predicted negative cases.
    - `cm[1,1]`: True Positives (TP) - Correctly predicted positive cases.
"""

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print(cm)

"""This section of the script visualizes the confusion matrix to better understand the model's classification performance."""

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay
n_classes = cm.shape[0]
classes = [str(i) for i in range(n_classes)]

disp = ConfusionMatrixDisplay(confusion_matrix=cm.T, display_labels=classes)
disp.plot()
plt.xlabel("True Label")
plt.ylabel("Predicted Label")
plt.show()

"""This section of the script evaluates the performance of the trained logistic regression model using key classification metrics."""

from sklearn.metrics import precision_score,accuracy_score,f1_score,recall_score
print("The accuracy score is:", accuracy_score(y_test, y_pred))
print("The precision score is:", precision_score(y_test, y_pred, average='macro'))
print("The recall score is:",recall_score(y_test, y_pred, average='macro'))
print("The f1_score score is:", f1_score(y_test, y_pred, average='macro'))

"""This section of the script plots the ROC curve to evaluate the classifier's performance."""

from sklearn.metrics import roc_curve, auc
y_prob = classifier.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', color='blue')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

"""# **KNN Classification**

The code initializes and trains a KNN classifier from sklearn.neighbors. The parameter n_neighbors=5 specifies that the model will consider the 5 nearest neighbors for classification. The metric='minkowski' with p=2 configures the distance measurement as Euclidean distance. The fit method trains the classifier using X_train and y_train, enabling it to classify new data based on the majority class of the nearest neighbors.
"""

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
classifier.fit(X_train, y_train)

"""The code y_pred = classifier.predict(X_test) predicts class labels for the test dataset X_test using the trained K-Nearest Neighbors (KNN) classifier."""

y_pred = classifier.predict(X_test)

"""The code calculates and prints the confusion matrix for the model's predictions. The confusion_matrix(y_test, y_pred) function from sklearn.metrics compares the true labels (y_test) with the predicted labels (y_pred), providing a summary of correct and incorrect classifications. The printed confusion matrix helps evaluate the model’s performance by showing true positives, true negatives, false positives, and false negatives."""

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print(cm)

"""This section of the script visualizes the confusion matrix to better understand the model's classification performance."""

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay
n_classes = cm.shape[0]
classes = [str(i) for i in range(n_classes)]

disp = ConfusionMatrixDisplay(confusion_matrix=cm.T, display_labels=classes)
disp.plot()
plt.xlabel("True Label")
plt.ylabel("Predicted Label")
plt.show()

"""The code evaluates the classification model’s performance using various metrics from sklearn.metrics. It prints the accuracy, precision, recall, and F1-score based on the true labels (y_test) and predicted labels (y_pred)."""

from sklearn.metrics import precision_score,accuracy_score,f1_score,recall_score
print("The accuracy score is:", accuracy_score(y_test, y_pred))
print("The precision score is:", precision_score(y_test, y_pred, average='macro'))
print("The recall score is:",recall_score(y_test, y_pred, average='macro'))
print("The f1_score score is:", f1_score(y_test, y_pred, average='macro'))

"""This section of the script plots the ROC curve to evaluate the classifier's performance."""

from sklearn.metrics import roc_curve, auc
y_prob = classifier.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', color='blue')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

"""# **Support Vector Classification**

The code initializes and trains a Support Vector Machine (SVM) classifier using the Radial Basis Function (RBF) kernel. The SVC class from sklearn.svm is used, with kernel='rbf' to handle non-linearly separable data. The random_state=0 ensures reproducibility, and probability=True enables probability estimates for predictions. The fit method trains the model using X_train and y_train, allowing it to classify new data based on learned decision boundaries.
"""

from sklearn.svm import SVC
classifier = SVC(kernel='rbf', random_state=0, probability=True)
classifier.fit(X_train, y_train)

"""The code y_pred = classifier.predict(X_test) predicts class labels for the test dataset X_test using the trained SVM classifier."""

y_pred = classifier.predict(X_test)

"""The code computes and prints the confusion matrix using confusion_matrix(y_test, y_pred) from sklearn.metrics. The confusion matrix evaluates the model’s performance by displaying the number of true positives, true negatives, false positives, and false negatives, helping to assess classification accuracy and error distribution."""

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print(cm)

"""This section of the script visualizes the confusion matrix to better understand the model's classification performance."""

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay
n_classes = cm.shape[0]
classes = [str(i) for i in range(n_classes)]

disp = ConfusionMatrixDisplay(confusion_matrix=cm.T, display_labels=classes)
disp.plot()
plt.xlabel("True Label")
plt.ylabel("Predicted Label")
plt.show()

"""The code evaluates the classification model’s performance using various metrics from sklearn.metrics. It prints the accuracy, precision, recall, and F1-score based on the true labels (y_test) and predicted labels (y_pred)."""

from sklearn.metrics import precision_score,accuracy_score,f1_score,recall_score
print("The accuracy score is:", accuracy_score(y_test, y_pred))
print("The precision score is:", precision_score(y_test, y_pred, average='macro'))
print("The recall score is:",recall_score(y_test, y_pred, average='macro'))
print("The f1_score score is:", f1_score(y_test, y_pred, average='macro'))

"""This section of the script plots the ROC curve to evaluate the classifier's performance."""

from sklearn.metrics import roc_curve, auc
y_prob = classifier.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', color='blue')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

"""# **Gaussian Naive Bayes**

The code initializes and trains a Gaussian Naïve Bayes (GaussianNB) classifier using GaussianNB() from sklearn.naive_bayes. This model assumes that features follow a normal (Gaussian) distribution. The fit method trains the classifier using X_train and y_train, enabling it to classify new data based on probability estimates derived from Bayes’ theorem.
"""

from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)

"""The code y_pred = classifier.predict(X_test) predicts class labels for the test dataset X_test using the trained Gaussian Naïve Bayes classifier."""

y_pred = classifier.predict(X_test)

"""The code calculates and prints the confusion matrix using confusion_matrix(y_test, y_pred) from sklearn.metrics. This matrix helps evaluate the model’s performance by displaying the number of true positives, true negatives, false positives, and false negatives, providing insights into classification accuracy and errors."""

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print(cm)

"""This section of the script visualizes the confusion matrix to better understand the model's classification performance."""

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay
n_classes = cm.shape[0]
classes = [str(i) for i in range(n_classes)]

disp = ConfusionMatrixDisplay(confusion_matrix=cm.T, display_labels=classes)
disp.plot()
plt.xlabel("True Label")
plt.ylabel("Predicted Label")
plt.show()

"""This section of the script evaluates the performance of the trained Classification model using key classification metrics."""

from sklearn.metrics import precision_score,accuracy_score,f1_score,recall_score
print("The accuracy score is:", accuracy_score(y_test, y_pred))
print("The precision score is:", precision_score(y_test, y_pred, average='macro'))
print("The recall score is:",recall_score(y_test, y_pred, average='macro'))
print("The f1_score score is:", f1_score(y_test, y_pred, average='macro'))

"""This section of the script plots the ROC curve to evaluate the classifier's performance."""

from sklearn.metrics import roc_curve, auc
y_prob = classifier.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', color='blue')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

"""# **Random Forest Classification**

The code initializes and trains a Random Forest classifier using RandomForestClassifier from sklearn.ensemble. The parameter n_estimators=100 specifies that the model will use 100 decision trees to make predictions, improving accuracy and reducing overfitting. The random_state=None ensures randomness in tree building, leading to slightly different results on each run. The fit method trains the model using X_train and y_train, enabling it to classify new data based on majority voting from multiple decision trees.
"""

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators=45, random_state=None)  # Adjust n_estimators as needed
classifier.fit(X_train, y_train)

"""The code y_pred = classifier.predict(X_test) predicts class labels for the test dataset X_test using the trained Random Forest classifier, aggregating results from multiple decision trees for improved accuracy and robustness."""

y_pred = classifier.predict(X_test)

"""This section of the script evaluates the performance of the trained classifier using a confusion matrix. The confusion matrix provides a summary of classification performance: - cm[0,0]: True Negatives (TN) - Correctly predicted negative cases. - cm[0,1]: False Positives (FP) - Incorrectly predicted positive cases. - cm[1,0]: False Negatives (FN) - Incorrectly predicted negative cases. - cm[1,1]: True Positives (TP) - Correctly predicted positive cases."""

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print(cm)

"""This section of the script visualizes the confusion matrix to better understand the model's classification performance."""

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay
n_classes = cm.shape[0]
classes = [str(i) for i in range(n_classes)]

disp = ConfusionMatrixDisplay(confusion_matrix=cm.T, display_labels=classes)
disp.plot()
plt.xlabel("True Label")
plt.ylabel("Predicted Label")
plt.show()

"""This section of the script evaluates the performance of the trained Classification model using key classification metrics."""

from sklearn.metrics import precision_score,accuracy_score,f1_score,recall_score
print("The accuracy score is:", accuracy_score(y_test, y_pred))
print("The precision score is:", precision_score(y_test, y_pred, average='macro'))
print("The recall score is:",recall_score(y_test, y_pred, average='macro'))
print("The f1_score score is:", f1_score(y_test, y_pred, average='macro'))

"""This section of the script plots the ROC curve to evaluate the classifier's performance."""

from sklearn.metrics import roc_curve, auc
y_prob = classifier.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', color='blue')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

"""# **Decision Tree Classification**

The code initializes and trains a Decision Tree classifier using DecisionTreeClassifier from sklearn.tree. The random_state=None allows the model to create different tree structures on each run due to randomness in splitting criteria. The fit method trains the classifier using X_train and y_train, enabling it to classify new data based on learned decision rules.
"""

from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier(random_state=None)
classifier.fit(X_train, y_train)

"""The code y_pred = classifier.predict(X_test) predicts class labels for the test dataset X_test using the trained Decision Tree classifier."""

y_pred = classifier.predict(X_test)

"""This section of the script evaluates the performance of the trained classifier using a confusion matrix. The confusion matrix provides a summary of classification performance: - cm[0,0]: True Negatives (TN) - Correctly predicted negative cases. - cm[0,1]: False Positives (FP) - Incorrectly predicted positive cases. - cm[1,0]: False Negatives (FN) - Incorrectly predicted negative cases. - cm[1,1]: True Positives (TP) - Correctly predicted positive cases."""

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print(cm)

"""This section of the script visualizes the confusion matrix to better understand the model's classification performance."""

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay
n_classes = cm.shape[0]
classes = [str(i) for i in range(n_classes)]

disp = ConfusionMatrixDisplay(confusion_matrix=cm.T, display_labels=classes)
disp.plot()
plt.xlabel("True Label")
plt.ylabel("Predicted Label")
plt.show()

"""This section of the script evaluates the performance of the trained Classification model using key classification metrics."""

from sklearn.metrics import precision_score,accuracy_score,f1_score,recall_score
print("The accuracy score is:", accuracy_score(y_test, y_pred))
print("The precision score is:", precision_score(y_test, y_pred, average='macro'))
print("The recall score is:",recall_score(y_test, y_pred, average='macro'))
print("The f1_score score is:", f1_score(y_test, y_pred, average='macro'))

"""This section of the script plots the ROC curve to evaluate the classifier's performance."""

from sklearn.metrics import roc_curve, auc
y_prob = classifier.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', color='blue')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()